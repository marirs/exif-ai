[package]
name = "exif-ai"
version = "0.2.0"
edition = "2024"
description = "AI-powered EXIF metadata writer — generate SEO titles, descriptions, tags, GPS, and subject data for images"
license = "MIT"
repository = "https://github.com/marirs/exif-ai"
authors = ["Sriram Govindan"]
exclude = [".github", "docs", "tests", "examples", "target", "Cargo.lock", "data"]
keywords = ["exif", "metadata", "ai", "gps", "image"]
categories = ["multimedia::images", "command-line-utilities"]

[lib]
name = "exif_ai"
path = "src/lib.rs"

[[bin]]
name = "exif-ai-cli"
path = "src/cli/main.rs"
required-features = ["cli"]

[features]
default = ["cli"]
cli = ["clap", "env_logger"]

[dependencies]
# CLI (optional — only needed for the binary)
clap = { version = "4", features = ["derive"], optional = true }

# Async runtime
tokio = { version = "1", features = ["full"] }

# HTTP client
reqwest = { version = "0.12", features = ["json", "rustls-tls"], default-features = false }

# Serialization
serde = { version = "1", features = ["derive"] }
serde_json = "1"

# Image handling
image = { version = "0.25", features = ["jpeg", "png", "webp"] }
base64 = "0.22"

# EXIF read
nom-exif = "2.7"

# EXIF/metadata write
little_exif = "0.4"
img-parts = "0.3"

# Logging
env_logger = { version = "0.11", optional = true }
log = "0.4"

# Error handling
anyhow = "1"

# Async trait
async-trait = "0.1"

# Local AI model (BLIP image captioning)
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"
tokenizers = { version = "0.21", default-features = false, features = ["onig"] }
hf-hub = { version = "0.4", default-features = false, features = ["tokio", "rustls-tls"] }

# File walking
walkdir = "2"

# macOS: use Accelerate (BLAS) + Metal (GPU) for fast Apple Silicon inference
[target.'cfg(target_os = "macos")'.dependencies]
accelerate-src = "0.3"
candle-core = { version = "0.8", features = ["accelerate", "metal"] }

[dev-dependencies]
tempfile = "3"
